{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning (EE-559) Mini-Project\n",
    "Members:\n",
    "Luca Salvador,\n",
    "Marco Giuliano,\n",
    "Paolo Giaretta\n",
    "#\n",
    "Professor:\n",
    "Andrea Cavallaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAUROC\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './code')\n",
    "from trainer import BimodalTrainer\n",
    "from GANtrainer import GANTrainer\n",
    "from models import Classifier, Generator\n",
    "from dataset_utils import BimodalDataset\n",
    "from utils import evaluate_cos_similarities\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up seed and device\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Setup dataset path\n",
    "\n",
    "cd = os.getcwd()\n",
    "\n",
    "data_path = os.path.join(cd, 'data')\n",
    "\n",
    "# Print\n",
    "print('Device:', device)\n",
    "print('Data path:', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_folder_name = 'hateful_memes'\n",
    "dataset_path = os.path.join(data_path, dataset_folder_name)\n",
    "train_path = os.path.join(dataset_path, 'train.pth')\n",
    "val_path = os.path.join(dataset_path, 'dev_unseen.pth')\n",
    "test_path = os.path.join(dataset_path, 'test_unseen.pth')\n",
    "\n",
    "# Load dataset (train-only for now)\n",
    "train_data = torch.load(train_path)\n",
    "val_data = torch.load(val_path)\n",
    "test_data = torch.load(test_path)\n",
    "\n",
    "# Calculate labels count for each\n",
    "train_labels = [x['label'] for x in train_data]\n",
    "val_labels = [x['label'] for x in val_data]\n",
    "test_labels = [x['label'] for x in test_data]\n",
    "\n",
    "print('Train data:', train_data[0].keys(), len(train_data), Counter(train_labels))\n",
    "print('Val data:', val_data[0].keys(), len(val_data), Counter(val_labels))\n",
    "print('Test data:', test_data[0].keys(), len(test_data), Counter(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN HYPERPARAMETERS #\n",
    "\n",
    "# Label to train on\n",
    "GAN_label = 1                       # 0: non-offensive, 1: offensive\n",
    "toxicity_threshold = 0.5            # Threshold to add generated data to the training set based on frozen-classifier\n",
    "similarilty_threshold = 0.5         # Threhold to add generated data to the training set based on similarity to the original data\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "epochs = 35\n",
    "num_gen_steps = 1\n",
    "num_disc_steps = 1\n",
    "\n",
    "# Loss weights\n",
    "lambda_gp = 0.5\n",
    "lambda_L1_gen = 0\n",
    "lambda_L2_gen = 1\n",
    "lambda_L1_disc = 0\n",
    "lambda_L2_disc = 1\n",
    "lambda_consistency = 0.2\n",
    "lambda_ms = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 1 to 2\n",
    "\n",
    "# Optimization\n",
    "lr_gen = 1e-4\n",
    "lr_disc =  3e-4\n",
    "gen_optimi = partial(optim.RMSprop, lr=lr_gen)\n",
    "disc_optim = partial(optim.RMSprop, lr=lr_disc)\n",
    "gen_scheduler = partial(StepLR, step_size=1, gamma=0.95)#from 0.99 to 1\n",
    "disc_scheduler = partial(StepLR, step_size=1, gamma=0.95)#from 0.99 to 1\n",
    "weight_cliping = None\n",
    "\n",
    "# Metrics\n",
    "metrics = {'acc_fake': BinaryAccuracy(), 'acc_real':BinaryAccuracy()}\n",
    "\n",
    "# Model ########################################################\n",
    "clip_feature_dim = 768\n",
    "\n",
    "# Generator\n",
    "noise_dim = 512\n",
    "gen_hidden_dims = [2*clip_feature_dim] * 2\n",
    "gen_dropout_prob = 0.2\n",
    "gen_normalize_features = False\n",
    "gen_bn = False\n",
    "\n",
    "# Discriminator\n",
    "classifier_hidden_dims = [256, 64]\n",
    "classifiers_dropout_prob = 0.38#from 0.5 to 0.3 \n",
    "comb_dropout_prob = 0.2\n",
    "comb_fusion = 'concat'\n",
    "disc_normalize_features = False\n",
    "disc_bn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for GAN generation\n",
    "train_data_filtered = list(filter(lambda x: x['label'] == GAN_label, train_data))\n",
    "print(f'Train dataset size after filtering on {GAN_label}:', len(train_data_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_dataset = BimodalDataset(train_data_filtered)\n",
    "train_dataloader_GAN  = DataLoader(GAN_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False,\n",
    "                              # sampler=CustomSampler()\n",
    "                              )\n",
    "\n",
    "# Check cosine similarity in dataset (for first batch)\n",
    "batch = next(iter(train_dataloader_GAN))\n",
    "img_embedding, text_embedding, _ = batch\n",
    "cos_sim_img, cos_sim_text = evaluate_cos_similarities(img_embedding, text_embedding)\n",
    "print(f'Mean cosine similarity in first batch \\n image: {cos_sim_img: .4f}, text: {cos_sim_text: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GAN models ########################################################\n",
    "gen = Generator(\n",
    "                 img_embedding_size=clip_feature_dim,\n",
    "                 text_embedding_size=clip_feature_dim,\n",
    "                 noise_dim=noise_dim,\n",
    "                 hidden_dims=gen_hidden_dims,\n",
    "                 dropout_prob=gen_dropout_prob,\n",
    "                 bn=gen_bn,\n",
    "                 act=\"relu\",\n",
    "                 normalize_features=gen_normalize_features\n",
    "                 ).to(device)\n",
    "\n",
    "disc = Classifier(\n",
    "                 clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=disc_bn,\n",
    "                 classifiers_dropout_prob=classifiers_dropout_prob,\n",
    "                 normalize_features=disc_normalize_features\n",
    "                 ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ########################################################\n",
    "# Define optimizers\n",
    "gen_optimizer = gen_optimi(gen.parameters())\n",
    "disc_optimizer = disc_optim(disc.parameters())\n",
    "\n",
    "# Define criterions\n",
    "# WGAN Losses\n",
    "gen_GAN_criterion = lambda prediction: -torch.mean(prediction) \n",
    "disc_GAN_criterion = lambda fake_predictions, real_predictions: -torch.mean(real_predictions) + torch.mean(fake_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN_trainer = GANTrainer(gen=gen,\n",
    "                    disc=disc,\n",
    "                    gen_optimizer=gen_optimizer,\n",
    "                    disc_optimizer=disc_optimizer,\n",
    "                    gen_scheduler=gen_scheduler(gen_optimizer),\n",
    "                    disc_scheduler=disc_scheduler(disc_optimizer),\n",
    "                    noise_dim=noise_dim,\n",
    "                    gen_GAN_criterion=gen_GAN_criterion,\n",
    "                    disc_GAN_criterion=disc_GAN_criterion,\n",
    "                    num_gen_steps=num_gen_steps,\n",
    "                    num_disc_steps=num_disc_steps,\n",
    "                    metrics=metrics,\n",
    "                    weight_clip=weight_cliping,\n",
    "                    lambda_gp=lambda_gp,\n",
    "                    lambda_L1_gen=lambda_L1_gen,\n",
    "                    lambda_L2_gen=lambda_L2_gen,\n",
    "                    lambda_L1_disc=lambda_L1_disc,\n",
    "                    lambda_L2_disc=lambda_L2_disc,\n",
    "                    lambda_consistency=lambda_consistency,\n",
    "                    lambda_ms=lambda_ms,\n",
    "                    device=device\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "dh = display(fig, display_id=True)\n",
    "\n",
    "path = os.path.join(cd, 'models/GAN.pth')\n",
    "GAN_trainer.train(train_dataloader_GAN, epochs, fig, dh)\n",
    "GAN_trainer.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER HYPERPARAMETERS ################################################################\n",
    "batch_size = 32\n",
    "\n",
    "# Loss weights\n",
    "lambda_L1 = 0\n",
    "lambda_L2 = 0\n",
    "\n",
    "# Optimization\n",
    "lr = 1e-3\n",
    "optimizer_fun = partial(optim.AdamW, lr=lr)\n",
    "scheduler_fun = partial(StepLR, step_size=1, gamma=0.8)\n",
    "\n",
    "# Metrics\n",
    "metrics = {'acc': BinaryAccuracy(), 'auroc': BinaryAUROC()}\n",
    "\n",
    "# Model\n",
    "clip_feature_dim = 768\n",
    "classifier_hidden_dims = [64]\n",
    "classifier_dropout_prob = 0.2\n",
    "comb_dropout_prob = 0.2\n",
    "comb_fusion = 'concat'\n",
    "normalize_features = False\n",
    "classifier_bn = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bimodal Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Bimodal trained on the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "classifier_bimodal = Classifier(\n",
    "                input_dim=clip_feature_dim,\n",
    "                comb_convex_tensor=False,\n",
    "                comb_proj=False, \n",
    "                comb_fusion=comb_fusion, \n",
    "                comb_dropout_prob=comb_dropout_prob,\n",
    "                classifier_hidden_dims=classifier_hidden_dims,\n",
    "                act=\"relu\",\n",
    "                bn=classifier_bn,\n",
    "                classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "train_dataset = BimodalDataset(train_data)\n",
    "val_dataset = BimodalDataset(val_data)\n",
    "\n",
    "# Define dataloaders (unbalanced)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False,\n",
    "                              )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            # sampler=CustomSampler(train_dataset)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier_bimodal.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = BimodalTrainer(classifier_bimodal,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "dh = display(fig, display_id=True)\n",
    "\n",
    "trainer.train(train_dataloader, val_dataloader, epochs, fig, dh)\n",
    "# Save\n",
    "path = os.path.join(cd, 'models/Classifier.pth')\n",
    "trainer.save(path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Bimodal trained with weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_bimodal = Classifier(\n",
    "                input_dim=clip_feature_dim,\n",
    "                comb_convex_tensor=False,\n",
    "                comb_proj=False, \n",
    "                comb_fusion=comb_fusion, \n",
    "                comb_dropout_prob=comb_dropout_prob,\n",
    "                classifier_hidden_dims=classifier_hidden_dims,\n",
    "                act=\"relu\",\n",
    "                bn=classifier_bn,\n",
    "                classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights\n",
    "length_train = len(train_data)\n",
    "labels_train = [x['label'] for x in train_data]\n",
    "weights = torch.tensor([1-(x / length_train) for x in Counter(labels_train).values()]).to(device)\n",
    "print('Weights:', weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "train_dataset = BimodalDataset(train_data)\n",
    "val_dataset = BimodalDataset(val_data)\n",
    "\n",
    "# Define dataloaders (unbalanced)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False,\n",
    "                              )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            # sampler=CustomSampler(train_dataset)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = lambda preds, labels: F.binary_cross_entropy_with_logits(preds.view(-1), labels, pos_weight=torch.gather(weights, dim=0, index=labels.type(torch.int64)))\n",
    "\n",
    "trainer = BimodalTrainer(classifier,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion,\n",
    "                        scheduler=scheduler,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "dh = display(fig, display_id=True)\n",
    "\n",
    "trainer.train(train_dataloader, val_dataloader, epochs, fig, dh)\n",
    "# Save\n",
    "path = os.path.join(cd, 'models/Classifier_weightsBalanced.pth')\n",
    "trainer.save(path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Bimodal trained on over sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_bimodal = Classifier(\n",
    "                input_dim=clip_feature_dim,\n",
    "                comb_convex_tensor=False,\n",
    "                comb_proj=False, \n",
    "                comb_fusion=comb_fusion, \n",
    "                comb_dropout_prob=comb_dropout_prob,\n",
    "                classifier_hidden_dims=classifier_hidden_dims,\n",
    "                act=\"relu\",\n",
    "                bn=classifier_bn,\n",
    "                classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_weights = torch.tensor([weights[x] for x in train_labels]).to(device)\n",
    "sampler = WeightedRandomSampler(individual_weights, len(train_data))\n",
    "\n",
    "# Define dataloader\n",
    "train_dataset = BimodalDataset(train_data)\n",
    "val_dataset = BimodalDataset(val_data)\n",
    "\n",
    "# Define dataloaders (balanced)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=False,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False,\n",
    "                              sampler=sampler\n",
    "                              )\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = BimodalTrainer(classifier,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "dh = display(fig, display_id=True)\n",
    "\n",
    "trainer.train(train_dataloader, val_dataloader, epochs, fig, dh)\n",
    "# Save\n",
    "path = os.path.join(cd, 'models/Classifier_samplerBalanced.pth')\n",
    "trainer.save(path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Bimodal trained on GAN augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2142120098.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    4) Bimodal on GAN data\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "classifier_bimodal = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bimodal.load_state_dict(torch.load('models/Classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze classifier_bimodal\n",
    "for param in classifier_bimodal.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_from_train = torch.cat([x['image'] for x in train_data_filtered], dim=0).float()\n",
    "text_from_train = torch.cat([x['text'] for x in train_data_filtered], dim=0).float()\n",
    "img_from_train= F.normalize(img_from_train, p=2, dim=-1).cpu()\n",
    "text_from_train = F.normalize(text_from_train, p=2, dim=-1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "num_samples_to_add = 300\n",
    "generated_data = torch.zeros(num_samples_to_add, 2, 768).to(device)\n",
    "prediction_threshold = 1\n",
    "similarilty_threshold = 1\n",
    "sim_df_L = 0\n",
    "sim_df_U = 0.75\n",
    "count = 0\n",
    "\n",
    "gen.eval()\n",
    "classifier_bimodal.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        # Generate data\n",
    "        noise = torch.randn(1, noise_dim).to(device)\n",
    "        image, text = gen(noise)\n",
    "\n",
    "\n",
    "        # Predict\n",
    "        prediction = classifier_bimodal(image, text)\n",
    "        predicton = F.sigmoid(prediction)\n",
    "        if prediction < prediction_threshold:\n",
    "            # Normalize\n",
    "            image_norm = F.normalize(image, p=2, dim=-1)\n",
    "            text_norm = F.normalize(text, p=2, dim=-1)\n",
    "\n",
    "            if count == 0:\n",
    "                generated_data[count, 0, :]=image\n",
    "                generated_data[count, 1, :]=text\n",
    "                count+=1\n",
    "                continue\n",
    "\n",
    "            # Similarity cosine with generated data\n",
    "            generated_data_img = F.normalize(generated_data[:count, 0, :], p=2, dim=-1)\n",
    "            generated_data_text = F.normalize(generated_data[:count, 1, :], p=2, dim=-1)\n",
    "\n",
    "            cos_sim_img = torch.mm(generated_data_img, image_norm.T).cpu()\n",
    "            cos_sim_text = torch.mm(generated_data_text, text_norm.T).cpu()\n",
    "\n",
    "            sim = max(cos_sim_img.max(), cos_sim_text.max())\n",
    "\n",
    "            # similarity cosing with original data\n",
    "\n",
    "            cos_sim_img_df = torch.mm(img_from_train, image_norm.T).cpu()\n",
    "            cos_sim_text_df = torch.mm(text_from_train, text_norm.T).cpu()\n",
    "\n",
    "            sim_gen = max(cos_sim_img_df.max(), cos_sim_text_df.max())\n",
    "\n",
    "\n",
    "            if sim < similarilty_threshold and (sim_gen > sim_df_L and sim_gen < sim_df_U):\n",
    "                generated_data[count, 0, :]=image\n",
    "                generated_data[count, 1, :]=text\n",
    "                count+=1\n",
    "                print(f\"Added {count} samples, remainig data {num_samples-i} samples.\")\n",
    "                if count==num_samples_to_add:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join generated data with train dataset\n",
    "# 1. Transform generated data into list of dicts\n",
    "generated_data_list =[{'image': generated_data[i, 0, :], 'text': generated_data[i, 1, :], 'label': GAN_label} for i in range(count)]\n",
    "\n",
    "# 2. Add generated data to the train dataset\n",
    "train_data_GAN = train_data + generated_data_list\n",
    "print(len(train_data_GAN))\n",
    "\n",
    "\n",
    "# 3. Define dataloader\n",
    "train_dataset_GAN = BimodalDataset(train_data_GAN)\n",
    "train_dataloader_GAN = DataLoader(train_dataset_GAN, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False,\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bimodal_gen = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "length_train = len(train_data_GAN)\n",
    "labels_train = [x['label'] for x in train_data_GAN]\n",
    "weights = torch.tensor([1-(x / length_train) for x in Counter(labels_train).values()]).to(device)\n",
    "\n",
    "criterion = lambda preds, labels: F.binary_cross_entropy_with_logits(preds.view(-1), labels, pos_weight=torch.gather(weights, dim=0, index=labels.type(torch.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the new dataset\n",
    "# Unfreeze the classifier\n",
    "for param in classifier_bimodal_gen.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# TRAINER ################################################################\n",
    "lr = 5e-4\n",
    "optimizer = optim.AdamW(classifier_bimodal_gen.parameters(), lr=lr)\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "metrics = {'acc': BinaryAccuracy(), 'auroc': BinaryAUROC()}\n",
    "\n",
    "trainer = BimodalTrainer(classifier_bimodal_gen,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "dh = display(fig, display_id=True)\n",
    "\n",
    "trainer.train(train_dataloader, val_dataloader, epochs, fig, dh)\n",
    "# Save\n",
    "path = os.path.join(cd, 'models/Classifier_GANBalanced.pth')\n",
    "trainer.save(path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Bimodal trained on the unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "classifier_bimodal = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bimodal.load_state_dict(torch.load('models/Classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier_bimodal.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = BimodalTrainer(classifier_bimodal,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_dataset = BimodalDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            )\n",
    "\n",
    "trainer.evaluate(test_dataloader)\n",
    "for metric, value in trainer.val_metrics_log.items():\n",
    "    print(f'{metric}: {value[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Bimodal trained with weighted loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "classifier = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_state_dict(torch.load('models/Classifier_weightsBalanced.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = lambda preds, labels: F.binary_cross_entropy_with_logits(preds.view(-1), labels, pos_weight=torch.gather(weights, dim=0, index=labels.type(torch.int64)))\n",
    "\n",
    "trainer = BimodalTrainer(classifier,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion,\n",
    "                        scheduler=scheduler,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_dataset = BimodalDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            )\n",
    "\n",
    "trainer.evaluate(test_dataloader)\n",
    "for metric, value in trainer.val_metrics_log.items():\n",
    "    print(f'{metric}: {value[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Bimodal trained on over sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "classifier = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_state_dict(torch.load('models/Classifier_samplerBalanced.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINER ################################################################\n",
    "optimizer = optimizer_fun(classifier.parameters())\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "trainer = BimodalTrainer(classifier,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_dataset = BimodalDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            )\n",
    "\n",
    "trainer.evaluate(test_dataloader)\n",
    "for metric, value in trainer.val_metrics_log.items():\n",
    "    print(f'{metric}: {value[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Bimodal trained on GAN augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bimodal_gen = Classifier(\n",
    "                 input_dim=clip_feature_dim,\n",
    "                 comb_convex_tensor=False,\n",
    "                 comb_proj=False, \n",
    "                 comb_fusion=comb_fusion, \n",
    "                 comb_dropout_prob=comb_dropout_prob,\n",
    "                 classifier_hidden_dims=classifier_hidden_dims,\n",
    "                 act=\"relu\",\n",
    "                 bn=classifier_bn,\n",
    "                 classifiers_dropout_prob=classifier_dropout_prob,\n",
    "                 normalize_features=normalize_features\n",
    "                ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_bimodal_gen.load_state_dict(torch.load('models/Classifier_GANBalanced.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier on the new dataset\n",
    "# Unfreeze the classifier\n",
    "for param in classifier_bimodal_gen.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# TRAINER ################################################################\n",
    "lr = 5e-4\n",
    "optimizer = optim.AdamW(classifier_bimodal_gen.parameters(), lr=lr)\n",
    "scheduler = scheduler_fun(optimizer)\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "metrics = {'acc': BinaryAccuracy(), 'auroc': BinaryAUROC()}\n",
    "\n",
    "trainer = BimodalTrainer(classifier_bimodal_gen,\n",
    "                        optimizer=optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        criterion=criterion,\n",
    "                        metrics=metrics,\n",
    "                        lambda_L1=lambda_L1,\n",
    "                        lambda_L2=lambda_L2,\n",
    "                        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_dataset = BimodalDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            )\n",
    "\n",
    "trainer.evaluate(test_dataloader)\n",
    "for metric, value in trainer.val_metrics_log.items():\n",
    "    print(f'{metric}: {value[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
